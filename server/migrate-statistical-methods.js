import { initDatabase, getPool } from './database.js';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import fs from 'fs/promises';

// è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// åˆ›å»ºç»Ÿè®¡æ–¹æ³•è¡¨
const createStatisticalMethodsTable = async (pool) => {
  console.log('åˆ›å»ºç»Ÿè®¡æ–¹æ³•è¡¨...');
  
  const createTableSQL = `
    CREATE TABLE IF NOT EXISTS statistical_methods (
      id INT AUTO_INCREMENT PRIMARY KEY,
      title VARCHAR(255) NOT NULL,
      keywords TEXT,
      content LONGTEXT NOT NULL,
      file_source VARCHAR(255),
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      INDEX idx_title (title),
      FULLTEXT(title, keywords, content)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
  `;
  
  await pool.execute(createTableSQL);
  console.log('âœ… ç»Ÿè®¡æ–¹æ³•è¡¨åˆ›å»ºæˆåŠŸ');
};

// è§£æmarkdownæ–‡ä»¶ï¼Œæå–æ ‡é¢˜å’Œå…³é”®è¯
const parseMarkdownFile = (content, filename) => {
  // æå–ä¸»æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª # æ ‡é¢˜ï¼‰
  const titleMatch = content.match(/^#\s+(.+)$/m);
  const title = titleMatch ? titleMatch[1].trim() : filename.replace('.md', '');
  
  // æå–å…³é”®è¯ - ä»æ ‡é¢˜å’Œå†…å®¹ä¸­
  const keywords = extractKeywords(title, content);
  
  return {
    title,
    keywords: keywords.join(', '),
    content,
    file_source: filename
  };
};

// ä»æ ‡é¢˜å’Œå†…å®¹ä¸­æå–å…³é”®è¯
const extractKeywords = (title, content) => {
  const keywords = new Set();
  
  // ä»æ ‡é¢˜ä¸­æå–å…³é”®è¯
  const titleKeywords = title.toLowerCase()
    .replace(/[()ï¼ˆï¼‰]/g, '')
    .split(/[\s,ï¼Œã€\/]+/)
    .filter(word => word.length > 1);
  
  titleKeywords.forEach(keyword => keywords.add(keyword));
  
  // ä»å†…å®¹ä¸­æå–ç»Ÿè®¡ç›¸å…³çš„å…³é”®è¯
  const statisticalTerms = [
    'æ£€éªŒ', 'test', 'åˆ†æ', 'analysis', 'æ–¹å·®', 'variance', 
    'å›å½’', 'regression', 'ç›¸å…³', 'correlation', 'æ˜¾è‘—æ€§', 'significance',
    'tæ£€éªŒ', 'anova', 'å¡æ–¹', 'chi-square', 'wilcoxon', 'éå‚æ•°',
    'å‡è®¾æ£€éªŒ', 'hypothesis test', 'ç½®ä¿¡åŒºé—´', 'confidence interval',
    'æ­£æ€åˆ†å¸ƒ', 'normal distribution', 'æ ‡å‡†å·®', 'standard deviation',
    'å‡å€¼', 'mean', 'ä¸­ä½æ•°', 'median', 'æ–¹å·®é½æ€§', 'homogeneity',
    'ç‹¬ç«‹æ€§', 'independence', 'é…å¯¹', 'paired', 'å•æ ·æœ¬', 'one sample',
    'åŒæ ·æœ¬', 'two sample', 'å¤šæ ·æœ¬', 'multiple sample'
  ];
  
  const contentLower = content.toLowerCase();
  statisticalTerms.forEach(term => {
    if (contentLower.includes(term.toLowerCase())) {
      keywords.add(term);
    }
  });
  
  // ä»markdownæ ‡é¢˜ä¸­æå–å…³é”®è¯
  const headingMatches = content.match(/^#{1,6}\s+(.+)$/gm);
  if (headingMatches) {
    headingMatches.forEach(heading => {
      const headingText = heading.replace(/^#+\s+/, '').toLowerCase();
      const headingWords = headingText.split(/[\s,ï¼Œã€\/]+/)
        .filter(word => word.length > 1);
      headingWords.forEach(word => keywords.add(word));
    });
  }
  
  return Array.from(keywords);
};

// è¯»å–assetç›®å½•ä¸‹çš„æ‰€æœ‰mdæ–‡ä»¶
const readAssetFiles = async () => {
  const assetDir = join(__dirname, '..', 'asset');
  console.log('è¯»å–assetç›®å½•:', assetDir);
  
  try {
    const files = await fs.readdir(assetDir);
    const mdFiles = files.filter(file => file.endsWith('.md'));
    
    console.log(`æ‰¾åˆ° ${mdFiles.length} ä¸ªmarkdownæ–‡ä»¶:`, mdFiles);
    
    const methods = [];
    
    for (const file of mdFiles) {
      const filePath = join(assetDir, file);
      try {
        const content = await fs.readFile(filePath, 'utf-8');
        const methodData = parseMarkdownFile(content, file);
        methods.push(methodData);
        console.log(`âœ… è§£ææ–‡ä»¶ ${file}: ${methodData.title}`);
      } catch (error) {
        console.error(`âŒ è¯»å–æ–‡ä»¶ ${file} å¤±è´¥:`, error);
      }
    }
    
    return methods;
  } catch (error) {
    console.error('âŒ è¯»å–assetç›®å½•å¤±è´¥:', error);
    return [];
  }
};

// å¯¼å…¥ç»Ÿè®¡æ–¹æ³•æ•°æ®åˆ°æ•°æ®åº“
const importStatisticalMethods = async (pool, methods) => {
  console.log(`å¼€å§‹å¯¼å…¥ ${methods.length} ä¸ªç»Ÿè®¡æ–¹æ³•...`);
  
  // æ¸…ç©ºç°æœ‰æ•°æ®
  await pool.execute('DELETE FROM statistical_methods WHERE file_source IS NOT NULL');
  console.log('å·²æ¸…ç©ºç°æœ‰çš„æ–‡ä»¶æ•°æ®');
  
  const insertSQL = `
    INSERT INTO statistical_methods (title, keywords, content, file_source)
    VALUES (?, ?, ?, ?)
  `;
  
  let successCount = 0;
  
  for (const method of methods) {
    try {
      await pool.execute(insertSQL, [
        method.title,
        method.keywords,
        method.content,
        method.file_source
      ]);
      successCount++;
      console.log(`âœ… å¯¼å…¥æˆåŠŸ: ${method.title}`);
    } catch (error) {
      console.error(`âŒ å¯¼å…¥å¤±è´¥ ${method.title}:`, error);
    }
  }
  
  console.log(`ğŸ‰ æˆåŠŸå¯¼å…¥ ${successCount}/${methods.length} ä¸ªç»Ÿè®¡æ–¹æ³•`);
};

// ä¸»å‡½æ•°
const main = async () => {
  console.log('ğŸš€ å¼€å§‹ç»Ÿè®¡æ–¹æ³•æ•°æ®è¿ç§»...');
  
  try {
    // åˆå§‹åŒ–æ•°æ®åº“
    const database = await initDatabase();
    const pool = getPool();
    
    // åˆ›å»ºè¡¨
    await createStatisticalMethodsTable(pool);
    
    // è¯»å–assetæ–‡ä»¶
    const methods = await readAssetFiles();
    
    if (methods.length === 0) {
      console.log('âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å…¥çš„æ–¹æ³•æ•°æ®');
      return;
    }
    
    // å¯¼å…¥æ•°æ®
    await importStatisticalMethods(pool, methods);
    
    // éªŒè¯å¯¼å…¥ç»“æœ
    const [result] = await pool.execute('SELECT COUNT(*) as count FROM statistical_methods');
    console.log(`ğŸ“Š æ•°æ®åº“ä¸­å…±æœ‰ ${result[0].count} ä¸ªç»Ÿè®¡æ–¹æ³•`);
    
    console.log('âœ… ç»Ÿè®¡æ–¹æ³•æ•°æ®è¿ç§»å®Œæˆï¼');
    
  } catch (error) {
    console.error('âŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:', error);
    process.exit(1);
  } finally {
    process.exit(0);
  }
};

// è¿è¡Œè¿ç§»
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export { main as migrateStatisticalMethods }; 